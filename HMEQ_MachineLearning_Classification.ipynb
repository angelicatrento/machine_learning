{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HMEQ_MachineLearning_Classification.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/angelicatrento/machine_learning/blob/master/HMEQ_MachineLearning_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OoasdhSAp0zJ"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "cIrwotvGqsYh",
        "colab": {}
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "C81KT2D_j-xR"
      },
      "source": [
        "# HMQE Machine Learning Classification Solution\n",
        "\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://drive.google.com/open?id=1q15JVawG1wC2u2YZM-mLrlDcTtV7Fkcu\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/angelicatrento/machine_learning/blob/master/HMEQ_MachineLearning_Classification.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "  <!--td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/r2/tutorials/estimators/lin.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td-->\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tUP8LMdYtWPz"
      },
      "source": [
        "## Overview\n",
        "\n",
        "This jupyter notebook uses tensorflow API and sk-learn to solve the HMEQ Classification Problem.\n",
        "This data has 13 features and the target variable is a binary of Default (1) or Not defaulted Loan (0).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vkC_j6VpqrDw"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rutbJGmpqvm3",
        "colab": {}
      },
      "source": [
        "!pip install sklearn\n",
        "\n",
        "!pip install tensorflow-estimator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "54mb4J9PqqDh",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "from six.moves import urllib"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bNiwh-APcRVD",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow.compat.v2.feature_column as fc\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from matplotlib import pyplot as plt\n",
        "import math\n",
        "import seaborn as sns\n",
        "\n",
        "from IPython import display\n",
        "from matplotlib import cm\n",
        "from matplotlib import gridspec\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn import metrics\n",
        "##import tensorflow.contrib.learn.python.learn as ln\n",
        "##from tensorflow.contrib.learn.python.learn import learn_io, estimator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fsjkwfsGOBMT"
      },
      "source": [
        "## Load the dataset\n",
        "The target (BAD) is a binary variable indicating whether an applicant eventually defaulted or was seriously delinquent. This adverse outcome occurred in 1,189 cases (20%).\n",
        "For each applicant, 11 input variables were recorded.\n",
        "\n",
        "*   BAD : \n",
        "\n",
        "> 1 = client defaulted on loan\n",
        "\n",
        "> 0 = loan repaid\n",
        "\n",
        "*   LOAN : Amount of the loan request\n",
        "*   MORTDUE : Amount due on existing mortgage\n",
        "*   VALUE : Value of current property\n",
        "*   REASON : DebtCon = debt consolidation HomeImp = home improvement\n",
        "*   JOB : Six occupational categories\n",
        "*   YOJ : Years at present job\n",
        "*   DEROG : Number of major derogatory reports\n",
        "*   DELINQ : Number of delinquent credit lines\n",
        "*   CLAGE : Age of oldest trade line in months\n",
        "*   NINQ : Number of recent credit lines\n",
        "*   CLNO : Number of credit lines\n",
        "*   DEBTINC : Debt-to-income ratio\n",
        "\n",
        "*   List item\n",
        "*   List item\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DSeMKcx03d5R",
        "colab": {}
      },
      "source": [
        "#Load dataset \n",
        "file = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vSoYNcoKkdU3fIwWUXQMOEB_hWg3HR1qwd-LuSqrGKvgdHYqjKVTKaMdD9-ODE35Hykg4LraaMHnAFl/pub?gid=1831163667&single=true&output=csv';\n",
        "dfhmeq = pd.read_csv(file)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jjm4Qj0u7_cp"
      },
      "source": [
        "## Explore the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UrQzxKKh4d6u"
      },
      "source": [
        "The dataset contains the following features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rTjugo3n308g",
        "colab": {}
      },
      "source": [
        "dfhmeq.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "y86q1fj44lZs",
        "colab": {}
      },
      "source": [
        "dfhmeq.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8JSa_duD4tFZ"
      },
      "source": [
        "Dataset has 5960 examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Fs3Nu5pV4v5J",
        "colab": {}
      },
      "source": [
        "\n",
        "# Provide the names for the columns since the CSV file with the data does\n",
        "# not have a header row.\n",
        "feature_names = [\"BAD\",\"LOAN\",\"MORTDUE\",\"VALUE\" ,'REASON','JOB'\n",
        "                 ,\"YOJ\",\"DEROG\",\"DELINQ\"\n",
        ",\"CLAGE\",\"NINQ\",\"CLNO\",\"DEBTINC\"]\n",
        "\n",
        "numeric_feature_names = [\"BAD\",\"LOAN\",\"MORTDUE\",\"VALUE\" \n",
        "                 ,\"YOJ\",\"DEROG\",\"DELINQ\"\n",
        ",\"CLAGE\",\"NINQ\",\"CLNO\",\"DEBTINC\"]\n",
        "\n",
        "# Load source the data from a CSV file that is comma separated.\n",
        "loan_source_data = pd.read_csv(file, header=None,sep=',',skiprows=[0],names=feature_names, encoding='latin-1')\n",
        "\n",
        "loan_data_remove_missing = pd.read_csv(file, header=None,sep=',',skiprows=[0],usecols=[\"BAD\",\"LOAN\",\"MORTDUE\",\"VALUE\" ,'REASON','JOB'\n",
        "                 ,\"YOJ\",\"DEROG\",\"DELINQ\"\n",
        ",\"CLAGE\",\"NINQ\",\"CLNO\",\"DEBTINC\"],names=feature_names, encoding='latin-1')\n",
        "# Load in the data from a CSV file that is comma separated.\n",
        "loan_data = pd.read_csv(file, header=None,sep=',',skiprows=[0],usecols=[\"BAD\",\"LOAN\",\"MORTDUE\",\"VALUE\" ,'REASON','JOB'\n",
        "                 ,\"YOJ\",\"DEROG\",\"DELINQ\"\n",
        ",\"CLAGE\",\"NINQ\",\"CLNO\",\"DEBTINC\"],names=feature_names, encoding='latin-1')\n",
        "\n",
        "loan_data_clean = pd.read_csv(file, header=None,sep=',',skiprows=[0],usecols=[\"BAD\",\"LOAN\",\"MORTDUE\",\"VALUE\" ,'REASON','JOB'\n",
        "                 ,\"YOJ\",\"DEROG\",\"DELINQ\"\n",
        ",\"CLAGE\",\"NINQ\",\"CLNO\",\"DEBTINC\"],names=feature_names, encoding='latin-1')\n",
        "\n",
        "\n",
        "print(\"Data set loaded. Num examples: \", len(loan_data))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXZwprQDBnLV",
        "colab_type": "text"
      },
      "source": [
        "## Data cleanup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDUheYT5XtEd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loan_data_clean.fillna(loan_data_clean.mean(), inplace=True);\n",
        "\n",
        "loan_data_clean.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DItSwJ_B5B0f"
      },
      "source": [
        "We use fillna to deal with NaN values by adding the mean value in its place"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRU_tdhLIbQD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CATEGORICAL_COLUMNS = [\"REASON\",\"JOB\"]\n",
        "\n",
        "NUMERIC_COLUMNS = [\"LOAN\",\"MORTDUE\",\"VALUE\"\n",
        "                 ,\"YOJ\",\"DEROG\",\"DELINQ\"\n",
        ",\"CLAGE\",\"NINQ\",\"CLNO\",\"DEBTINC\",\"BAD\"]\n",
        "\n",
        "loan_data_clean = pd.read_csv(file, header=None,sep=',',skiprows=[0],usecols= [\"REASON\",\"JOB\",\"LOAN\",\"MORTDUE\",\"VALUE\"\n",
        "                 ,\"YOJ\",\"DEROG\",\"DELINQ\"\n",
        ",\"CLAGE\",\"NINQ\",\"CLNO\",\"DEBTINC\",\"BAD\"],names=feature_names, encoding='latin-1')\n",
        "\n",
        "loan_data_clean.dropna(axis=0, how='any', inplace=True)\n",
        "\n",
        "loan_data_clean = loan_data_clean.reindex(np.random.permutation(loan_data_clean.index))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hBwWgvcJo8b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LOAN = tf.feature_column.numeric_column(\"LOAN\")\n",
        "MORTDUE = tf.feature_column.numeric_column(\"MORTDUE\")\n",
        "VALUE = tf.feature_column.numeric_column(\"VALUE\")\n",
        "REASON = tf.feature_column.categorical_column_with_vocabulary_list(\"REASON\", ['DebtCon', 'HomeImp'])\n",
        "JOB = tf.feature_column.categorical_column_with_vocabulary_list(\"JOB\", ['Office', 'Other', 'ProfExe', 'Mgr', 'Sales', 'Self'])\n",
        "YOJ = tf.feature_column.numeric_column(\"YOJ\")\n",
        "DEROG = tf.feature_column.numeric_column(\"DEROG\")\n",
        "DELINQ = tf.feature_column.numeric_column(\"DELINQ\")\n",
        "CLAGE = tf.feature_column.numeric_column(\"CLAGE\")\n",
        "NINQ = tf.feature_column.numeric_column(\"NINQ\")\n",
        "CLNO = tf.feature_column.numeric_column(\"CLNO\")\n",
        "DEBTINC = tf.feature_column.numeric_column(\"DEBTINC\")\n",
        "feature_columns = [LOAN, MORTDUE, VALUE, REASON, JOB, YOJ, DEROG, DELINQ, CLAGE, NINQ, CLNO, DEBTINC]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AM-RsDzNfGlu",
        "colab": {}
      },
      "source": [
        "data=pd.read_csv(file)\n",
        "data.fillna(data.mean(), inplace=True);\n",
        "\n",
        "DEROG_x_DELINQ = tf.feature_column.crossed_column([\"DEROG\", \"DELINQ\"], hash_bucket_size=100)\n",
        "\n",
        "feature_columns = [LOAN, MORTDUE, VALUE, REASON, JOB, YOJ, DEROG, DELINQ, CLAGE, NINQ, CLNO, DEBTINC]\n",
        "\n",
        "feature_columns_derived = [LOAN, MORTDUE, VALUE, REASON, JOB, YOJ, DEROG, DELINQ, CLAGE, NINQ, CLNO, DEBTINC, DEROG_x_DELINQ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhJ_tBh0BYba",
        "colab_type": "text"
      },
      "source": [
        "## Features Histogram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RYeCMm7K40ZN",
        "colab": {}
      },
      "source": [
        "dfhmeq.BAD.hist(bins=20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDo8YhBkqd0-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dfhmeq.DEROG.hist(bins=20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rosO0aObGAq5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for feature_name in numeric_feature_names:\n",
        "  data.hist(column=feature_name,bins = 40,figsize=(10,4))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgN2Sjd2BtN1",
        "colab_type": "text"
      },
      "source": [
        "## Data analysis \n",
        "\n",
        "Plots of features to understand what is available for our training algorithm \n",
        "\n",
        "Also the heatmap to analyse the correlation of features and the target value BAD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "b03dVV9q5Dv2",
        "colab": {}
      },
      "source": [
        "dfhmeq.JOB.value_counts().plot(kind='barh')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HA3Rj5lf1re",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dfhmeq.REASON.value_counts().plot(kind='barh')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkwbxq7UX_Uc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corr = loan_data_clean.corr()\n",
        "\n",
        "#Plot figsize\n",
        "fig, ax = plt.subplots(figsize=(10,8))\n",
        "\n",
        "#Generate Color Map\n",
        "colormap = sns.diverging_palette(220, 10, as_cmap=True)\n",
        "\n",
        "#Generate Heat Map, allow annotations and place floats in map\n",
        "sns.heatmap(corr, cmap=colormap, annot=True, fmt=\".2f\")\n",
        "\n",
        "#Apply xticks\n",
        "plt.xticks(range(len(corr.columns)), corr.columns);\n",
        "\n",
        "#Apply yticks\n",
        "plt.yticks(range(len(corr.columns)), corr.columns)\n",
        "\n",
        "#show plot\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7NK-hORXqTW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for feature_name_1 in numeric_feature_names:\n",
        "    for feature_name_2 in numeric_feature_names:\n",
        "         if feature_name_1 != feature_name_2: \n",
        "             plt.xlabel(feature_name_1)\n",
        "             plt.ylabel(feature_name_2)\n",
        "             plt.scatter(loan_data_clean[feature_name_1],loan_data_clean[feature_name_2])\n",
        "             plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EKYOCa4EN_T",
        "colab_type": "text"
      },
      "source": [
        "## Train & Test Data\n",
        "\n",
        "The purpose of splitting the data is to be able to assess the quality of a predictive model. \n",
        "\n",
        "When training, we build a model that fits to the data as closely as possible, to be able to most accurately make a prediction. \n",
        "\n",
        "The split ratio is often 80 to 70% of the data for training and 20 to 30% of it for test/validation.\n",
        "One way of validating the model is to split the data into three sets: train, validation and test. Then we could use the training data to understand which classifier to use; the validation set to test and tweak parameters; and the test set to get an understanding of how your final model would work in practice. \n",
        "\n",
        "For the purpose of this project, we will only be randomly splitting our data into test and train.\n",
        "\n",
        "We will use the function train_test_split from the scikit-learn library\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBjeiAPlCx6n",
        "colab_type": "text"
      },
      "source": [
        "### Linear Regression\n",
        "We will first try a LinerRegression algorithm and plot the results "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5nEKZpHYXBi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loan_data_clean = loan_data_clean.reindex(np.random.permutation(loan_data_clean.index))\n",
        "\n",
        "loan_data_remove_missing.dropna(axis=0, how='any', inplace=True)\n",
        "loan_data_remove_missing = loan_data_remove_missing.reindex(np.random.permutation(loan_data_remove_missing.index))\n",
        "\n",
        "\n",
        "X_source = loan_data_remove_missing[['DEROG','DELINQ','YOJ']].values\n",
        "y_source = loan_data_remove_missing['BAD'].values\n",
        "\n",
        "X_source_training_data, X_source_test_data, y_source_training_data, y_source_test_data = train_test_split(X_source, y_source, test_size=0.3, random_state=0)\n",
        "\n",
        "regressor_source = LinearRegression()  \n",
        "regressor_source.fit(X_source_training_data, y_source_training_data)\n",
        "\n",
        "\n",
        "y_source_pred = regressor_source.predict(X_source_test_data)\n",
        "\n",
        "df_source = pd.DataFrame({'Actual': y_source_test_data, 'Predicted': y_source_pred})\n",
        "df1_source = df_source.head(25)\n",
        "\n",
        "df1_source"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uP7wwZfC5nC",
        "colab_type": "text"
      },
      "source": [
        "As we can see, we didn't achieve good results with a LinearRegression in our data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8t3opx0cZJdv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df1_source.plot(kind='bar',figsize=(10,8))\n",
        "plt.grid(which='major', linestyle='-', linewidth='0.5', color='green')\n",
        "plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwnWbVFNZM8G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Mean Absolute Error:', metrics.mean_absolute_error(y_source_test_data, y_source_pred))  \n",
        "print('Mean Squared Error:', metrics.mean_squared_error(y_source_test_data, y_source_pred))  \n",
        "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_source_test_data, y_source_pred)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pthBlkK_KrlW",
        "colab_type": "text"
      },
      "source": [
        "### Decision Tree Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jU4Qx4bZQR8_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.DELINQ, data.BAD, test_size=0.30, random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "from sklearn import tree\n",
        "\n",
        "c = tree.DecisionTreeClassifier()\n",
        "c.fit(X_train.values.reshape(-1, 1), y_train)\n",
        "\n",
        "y_test_size = y_test.size\n",
        "y_train_size = y_train.size\n",
        "\n",
        "accu_train = np.sum(c.predict(X_train.values.reshape(-1, 1)) == y_train)/y_train_size\n",
        "accu_test = np.sum(c.predict(X_test.values.reshape(-1, 1)) == y_test)/y_test_size\n",
        "\n",
        "print(\"Accuracy on Train: \", accu_train)\n",
        "print(\"Accuracy on Test: \", accu_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mS8Qa86-Iq_s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = (loan_data_clean.head(2673))\n",
        "test = (loan_data_clean.tail(691))\n",
        "\n",
        "\n",
        "feature_columns = []\n",
        "for feature_name in CATEGORICAL_COLUMNS:\n",
        "  vocabulary = train[feature_name].unique()\n",
        "  feature_columns.append(tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary))\n",
        "\n",
        "for feature_name in NUMERIC_COLUMNS:\n",
        "  feature_columns.append(tf.feature_column.numeric_column(feature_name, dtype=tf.float64))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlGjpO3OIxiv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9p0D9nZXLqM3",
        "colab_type": "text"
      },
      "source": [
        "### Models from sklearn \n",
        "\n",
        "We are going to test some different algorithms from the sk-learn library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2p-faoLaDSF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sc = StandardScaler()\n",
        "X_source_training_data = sc.fit_transform(X_source_training_data)\n",
        "X_source_test_data = sc.transform(X_source_test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eDSPfdgLy1h",
        "colab_type": "text"
      },
      "source": [
        "#### Random Forest Regressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLkeQ11laWWU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "regressor = RandomForestRegressor(n_estimators=2000, random_state=0)\n",
        "regressor.fit(X_source_training_data, y_source_training_data)\n",
        "y_pred = regressor.predict(X_source_training_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kQi3Nc2LpGf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_source_pred = regressor.predict(X_source_test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVcqpWayapzG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "print('Mean Absolute Error:', metrics.mean_absolute_error(y_source_test_data, y_source_pred))  \n",
        "print('Mean Squared Error:', metrics.mean_squared_error(y_source_test_data, y_source_pred))  \n",
        "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_source_test_data, y_source_pred)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uSyqSaELIH8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "df_source_new = pd.DataFrame({'Actual': y_source_test_data, 'Predicted': y_source_pred})\n",
        "df1_source_new = df_source_new.head(25)\n",
        "\n",
        "df1_source_new"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdkPfUA3MOdM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "df1_source_new.plot(kind='bar',figsize=(10,8))\n",
        "plt.grid(which='major', linestyle='-', linewidth='0.5', color='green')\n",
        "plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HI1YgZqlD5I9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Mean Absolute Error:', metrics.mean_absolute_error(y_source_test_data, y_source_pred))  \n",
        "print('Mean Squared Error:', metrics.mean_squared_error(y_source_test_data, y_source_pred))  \n",
        "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_source_test_data, y_source_pred)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "puZFOhTDkblt"
      },
      "source": [
        "### Percentage of BAD per REASON"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4vMwTxfP75-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CATEGORICAL_COLUMNS = [\"REASON\",\"JOB\"]\n",
        "\n",
        "NUMERIC_COLUMNS = [\"LOAN\",\"MORTDUE\",\"VALUE\"\n",
        "                 ,\"YOJ\",\"DEROG\",\"DELINQ\"\n",
        ",\"CLAGE\",\"NINQ\",\"CLNO\",\"DEBTINC\",\"BAD\"]\n",
        "\n",
        "loan_data_clean = pd.read_csv(file, header=None,sep=',',skiprows=[0],usecols= [\"REASON\",\"JOB\",\"LOAN\",\"MORTDUE\",\"VALUE\"\n",
        "                 ,\"YOJ\",\"DEROG\",\"DELINQ\"\n",
        ",\"CLAGE\",\"NINQ\",\"CLNO\",\"DEBTINC\",\"BAD\"],names=feature_names, encoding='latin-1')\n",
        "\n",
        "loan_data_clean.dropna(axis=0, how='any', inplace=True)\n",
        "\n",
        "loan_data_clean = loan_data_clean.reindex(np.random.permutation(loan_data_clean.index))\n",
        "\n",
        "\n",
        "train = (loan_data_clean.head(2673))\n",
        "test = (loan_data_clean.tail(691))\n",
        "\n",
        "\n",
        "#msk = np.random.rand(len(loan_data_clean)) < 0.8\n",
        "\n",
        "#train = loan_data_clean[msk]\n",
        "#print(train['BAD'].unique())\n",
        "#test = loan_data_clean[~msk]\n",
        "y_train = train.pop('BAD')\n",
        "y_eval = test.pop('BAD')\n",
        "\n",
        "#print(loan_data_clean)\n",
        "\n",
        "#X_source = loan_data_remove_missing[['DEROG','DELINQ','CLAGE']].values\n",
        "#y_source = loan_data_remove_missing['BAD'].values\n",
        "#X = loan_data_clean[['DEROG','DELINQ','CLAGE']].values\n",
        "#y = loan_data_clean['BAD'].values\n",
        "\n",
        "#X_source_training_data, X_source_test_data, y_source_training_data, y_source_test_data = train_test_split(X_source, y_source, test_size=0.2, random_state=0)\n",
        "\n",
        "feature_columns = []\n",
        "for feature_name in CATEGORICAL_COLUMNS:\n",
        "  vocabulary = train[feature_name].unique()\n",
        "  feature_columns.append(tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary))\n",
        "\n",
        "for feature_name in NUMERIC_COLUMNS:\n",
        "  feature_columns.append(tf.feature_column.numeric_column(feature_name, dtype=tf.float64))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-oGyT40mhTd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.concat([train, y_train], axis=1).groupby('REASON').BAD.mean().plot(kind='barh').set_xlabel('% BAD')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTd00xD3I8U7",
        "colab_type": "text"
      },
      "source": [
        "### Percentage of BAD per JOB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGhZTVgoSoaL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.concat([train, y_train], axis=1).groupby('JOB').BAD.mean().plot(kind='barh').set_xlabel('% BAD')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Gt8HMtwOh9lJ"
      },
      "source": [
        "The `input_function` specifies how data is converted to a `tf.data.Dataset` that feeds the input pipeline in a streaming fashion. `tf.data.Dataset` take take in multiple sources such as a dataframe, a csv-formatted file, and more."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qVtrIHFnAe7w",
        "colab": {}
      },
      "source": [
        "def make_input_fn(data_df, label_df, num_epochs=10, shuffle=True, batch_size=32):\n",
        "  def input_function():\n",
        "    ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))\n",
        "    if shuffle:\n",
        "      ds = ds.shuffle(1000)\n",
        "    ds = ds.batch(batch_size).repeat(num_epochs)\n",
        "    return ds\n",
        "  return input_function\n",
        "\n",
        "train_input_fn = make_input_fn(train, y_train)\n",
        "eval_input_fn = make_input_fn(test, y_eval, num_epochs=1, shuffle=False)\n",
        "\n",
        "make_input_fn(train, y_train)\n",
        "#print(dict(train[0]))\n",
        "#print(tf.data.Dataset.from_tensor_slices((dict(train), y_train)))\n",
        "#print(train_input_fn)\n",
        "#print(eval_input_fn)\n",
        "\n",
        "#my_dictionary = dict(train.head(1))\n",
        "#for name in my_dictionary.items():\n",
        "  #print (name )\n",
        "  #print(my_dictionaty)\n",
        "\n",
        "dict(train)\n",
        "#for name in my_dictionaty.items():\n",
        "#    my_dictionaty['\\'' + name + '\\''] = my_dictionaty.pop(name)\n",
        "    \n",
        "#print(my_dictionaty)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "P7UMVkQnkrgb"
      },
      "source": [
        "You can inspect the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8ZcG_3KiCb1M",
        "colab": {}
      },
      "source": [
        "ds = make_input_fn(train, y_train, batch_size=100)()\n",
        "\n",
        "print(ds.take(1))\n",
        "for feature_batch, label_batch in ds.take(1):\n",
        "  print('Some feature keys:', list(feature_batch.keys()))\n",
        "  print()\n",
        "  print('A batch of class:', feature_batch['LOAN'].numpy())\n",
        "  print()\n",
        "  print('A batch of Labels:', label_batch.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lMNBMyodjlW3"
      },
      "source": [
        "You can also inspect the result of a specific feature column using the `tf.keras.layers.DenseFeatures` layer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PzDu8qkMajN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IMjlmbPlDmkB",
        "colab": {}
      },
      "source": [
        "print(feature_columns)\n",
        "DELINQ_column = feature_columns[7]\n",
        "tf.keras.layers.DenseFeatures([DELINQ_column])(feature_batch).numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3S8c_ADZl_DF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(feature_columns)\n",
        "DEROG_column = feature_columns[6]\n",
        "tf.keras.layers.DenseFeatures([DEROG_column])(feature_batch).numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "f4zrAdCIjr3s"
      },
      "source": [
        "`DenseFeatures` only accepts dense tensors, to inspect a categorical column you need to transform that to a indicator column first:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1VXmXFTSFEvv",
        "colab": {}
      },
      "source": [
        "JOB_column = feature_columns[1]\n",
        "\n",
        "tf.keras.layers.DenseFeatures([tf.feature_column.indicator_column(JOB_column)])(feature_batch).numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e90vJ4L1GL3V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "train.REASON.unique()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MEp59g5UkHYY"
      },
      "source": [
        "After adding all the base features to the model, let's train the model. Training a model is just a single command using the `tf.estimator` API:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VE4PyluJMqI6",
        "colab_type": "text"
      },
      "source": [
        "#### Linear Classifier \n",
        "\n",
        "From tensor flow library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2thNhT4VSbzY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CATEGORICAL_COLUMNS = [\"REASON\",\"JOB\"]\n",
        "\n",
        "NUMERIC_COLUMNS = [\"LOAN\",\"MORTDUE\",\"VALUE\"\n",
        "                 ,\"YOJ\",\"DEROG\",\"DELINQ\"\n",
        ",\"CLAGE\",\"NINQ\",\"CLNO\",\"DEBTINC\",\"BAD\"]\n",
        "\n",
        "loan_data_clean = pd.read_csv(file, header=None,sep=',',skiprows=[0],usecols= [\"REASON\",\"JOB\",\"LOAN\",\"MORTDUE\",\"VALUE\"\n",
        "                 ,\"YOJ\",\"DEROG\",\"DELINQ\"\n",
        ",\"CLAGE\",\"NINQ\",\"CLNO\",\"DEBTINC\",\"BAD\"],names=feature_names, encoding='latin-1')\n",
        "\n",
        "loan_data_clean.dropna(axis=0, how='any', inplace=True)\n",
        "\n",
        "loan_data_clean = loan_data_clean.reindex(np.random.permutation(loan_data_clean.index))\n",
        "\n",
        "\n",
        "train = (loan_data_clean.head(2673))\n",
        "test = (loan_data_clean.tail(691))\n",
        "\n",
        "\n",
        "y_train = train.pop('BAD')\n",
        "y_eval = test.pop('BAD')\n",
        "\n",
        "\n",
        "feature_columns = []\n",
        "for feature_name in CATEGORICAL_COLUMNS:\n",
        "  vocabulary = train[feature_name].unique()\n",
        "  feature_columns.append(tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary))\n",
        "\n",
        "for feature_name in NUMERIC_COLUMNS:\n",
        "  feature_columns.append(tf.feature_column.numeric_column(feature_name, dtype=tf.float64))\n",
        "  \n",
        "  \n",
        "\n",
        "train_input_fn = make_input_fn(train, y_train)\n",
        "eval_input_fn = make_input_fn(test, y_eval, num_epochs=1, shuffle=False)\n",
        "\n",
        "make_input_fn(train, y_train)\n",
        "\n",
        "dict(train)\n",
        "#for name in my_dictionaty.items():\n",
        "#    my_dictionaty['\\'' + name + '\\''] = my_dictionaty.pop(name)\n",
        "    \n",
        "#print(my_dictionaty)\n",
        "\n",
        "\n",
        "ds = make_input_fn(train, y_train, batch_size=100)()\n",
        "\n",
        "print(ds.take(1))\n",
        "for feature_batch, label_batch in ds.take(1):\n",
        "  print('Some feature keys:', list(feature_batch.keys()))\n",
        "  print()\n",
        "  print('A batch of class:', feature_batch['LOAN'].numpy())\n",
        "  print()\n",
        "  print('A batch of Labels:', label_batch.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOZ2RydcSmSO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(feature_columns)\n",
        "DELINQ_column = feature_columns[7]\n",
        "tf.keras.layers.DenseFeatures([DELINQ_column])(feature_batch).numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quA1I6giSphr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "print(feature_columns)\n",
        "DEROG_column = feature_columns[6]\n",
        "tf.keras.layers.DenseFeatures([DEROG_column])(feature_batch).numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DqDFyPKQmGTN"
      },
      "source": [
        "After adding the combination feature to the model, let's train the model again:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-P-sjd9PSttj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "ds = make_input_fn(train, y_train, batch_size=10)()\n",
        "\n",
        "train.YOJ.unique()\n",
        "\n",
        "LOAN = tf.feature_column.numeric_column(\"LOAN\")\n",
        "MORTDUE = tf.feature_column.numeric_column(\"MORTDUE\")\n",
        "VALUE = tf.feature_column.numeric_column(\"VALUE\")\n",
        "REASON = tf.feature_column.categorical_column_with_vocabulary_list(\"REASON\", ['DebtCon', 'HomeImp'])\n",
        "JOB = tf.feature_column.categorical_column_with_vocabulary_list(\"JOB\", ['Office', 'Other', 'ProfExe', 'Mgr', 'Sales', 'Self'])\n",
        "YOJ = tf.feature_column.numeric_column(\"YOJ\")\n",
        "DEROG = tf.feature_column.numeric_column(\"DEROG\")\n",
        "DELINQ = tf.feature_column.numeric_column(\"DELINQ\")\n",
        "CLAGE = tf.feature_column.numeric_column(\"CLAGE\")\n",
        "NINQ = tf.feature_column.numeric_column(\"NINQ\")\n",
        "CLNO = tf.feature_column.numeric_column(\"CLNO\")\n",
        "DEBTINC = tf.feature_column.numeric_column(\"DEBTINC\")\n",
        "feature_columns = [LOAN, MORTDUE, VALUE, REASON, JOB, YOJ, DEROG, DELINQ, CLAGE, NINQ, CLNO, DEBTINC]\n",
        "\n",
        "\n",
        "tf.keras.backend.set_floatx('float64')\n",
        "linear_est = tf.estimator.LinearClassifier(feature_columns=feature_columns, model_dir=None, n_classes=30)\n",
        "linear_est.train(train_input_fn)\n",
        "result = linear_est.evaluate(eval_input_fn)\n",
        "\n",
        "clear_output()\n",
        "print(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abbUWY42S04q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DEROG_x_DELINQ = tf.feature_column.crossed_column([\"DEROG\", \"DELINQ\"], hash_bucket_size=100)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8lG0h4YS4tG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "derived_feature_columns = [DEROG_x_DELINQ]\n",
        "print(train_input_fn)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLWGaQadZewv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_names = [\"LOAN\",\"MORTDUE\",\"VALUE\",\"YOJ\",\"DEROG\",\"DELINQ\",\"CLAGE\",\"NINQ\",\"CLNO\",\"DEBTINC\",\"BAD\"]\n",
        "X = loan_data_clean[feature_names]\n",
        "y = loan_data_clean['BAD']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlCdoIReaAiV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rwfdZj7ImLwb"
      },
      "source": [
        "#### Logistic Regression "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gCG91UWaOgn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, y_train)\n",
        "print('Accuracy of Logistic regression classifier on training set: {:.2f}'\n",
        "     .format(logreg.score(X_train, y_train)))\n",
        "print('Accuracy of Logistic regression classifier on test set: {:.2f}'\n",
        "     .format(logreg.score(X_test, y_test)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxS76Q8iaXdx",
        "colab_type": "text"
      },
      "source": [
        "#### Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_acQw4OVaRqh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "clf = DecisionTreeClassifier().fit(X_train, y_train)\n",
        "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
        "     .format(clf.score(X_train, y_train)))\n",
        "print('Accuracy of Decision Tree classifier on test set: {:.2f}'\n",
        "     .format(clf.score(X_test, y_test)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPER1tTPaaX9",
        "colab_type": "text"
      },
      "source": [
        "#### KNN Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPNM0J_jaaj5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn = KNeighborsClassifier()\n",
        "knn.fit(X_train, y_train)\n",
        "print('Accuracy of K-NN classifier on training set: {:.2f}'\n",
        "     .format(knn.score(X_train, y_train)))\n",
        "print('Accuracy of K-NN classifier on test set: {:.2f}'\n",
        "     .format(knn.score(X_test, y_test)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nw-hk8zVEjU",
        "colab_type": "text"
      },
      "source": [
        "#### LDA classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgQ0sq-_ahEh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "lda = LinearDiscriminantAnalysis()\n",
        "lda.fit(X_train, y_train)\n",
        "print('Accuracy of LDA classifier on training set: {:.2f}'\n",
        "     .format(lda.score(X_train, y_train)))\n",
        "print('Accuracy of LDA classifier on test set: {:.2f}'\n",
        "     .format(lda.score(X_test, y_test)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_6RDVpVVHSQ",
        "colab_type": "text"
      },
      "source": [
        "#### Gaussian NB Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYJOE_qaak6u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(X_train, y_train)\n",
        "print('Accuracy of GNB classifier on training set: {:.2f}'\n",
        "     .format(gnb.score(X_train, y_train)))\n",
        "print('Accuracy of GNB classifier on test set: {:.2f}'\n",
        "     .format(gnb.score(X_test, y_test)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6FQP2p8VONT",
        "colab_type": "text"
      },
      "source": [
        "#### SVM Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaxISXZkan4x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "svm = SVC()\n",
        "svm.fit(X_train, y_train)\n",
        "print('Accuracy of SVM classifier on training set: {:.2f}'\n",
        "     .format(svm.score(X_train, y_train)))\n",
        "print('Accuracy of SVM classifier on test set: {:.2f}'\n",
        "     .format(svm.score(X_test, y_test)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHHLeT0Xarp6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "pred = knn.predict(X_test)\n",
        "print(confusion_matrix(y_test, pred))\n",
        "print(classification_report(y_test, pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWUqgNpRbMmz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "X = loan_data_clean[feature_names]\n",
        "y = loan_data_clean['BAD']\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqni44ved8B8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RN-oPpGoeCiH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "regressor = RandomForestRegressor(n_estimators=20, random_state=0)\n",
        "regressor.fit(X_train, y_train)\n",
        "y_pred = regressor.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHJdAiquVeTe",
        "colab_type": "text"
      },
      "source": [
        "#### Random Forest Regressor Report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGYH2_xHeF75",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(classification_report(y_test,y_pred))\n",
        "print(accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Or-L6QuOexFS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_source_new = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
        "df1_source_new = df_source_new.head(25)\n",
        "\n",
        "\n",
        "df1_source_new.plot(kind='bar',figsize=(10,8))\n",
        "plt.grid(which='major', linestyle='-', linewidth='0.5', color='green')\n",
        "plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWYhB5foU31j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}